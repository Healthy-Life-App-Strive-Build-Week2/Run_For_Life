{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00000-143780d1-a7b6-4bac-b861-d2378912cd00",
    "deepnote_cell_type": "code"
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# GoogleFit Journey Classifier\n\n## A product by Team GoogleFit\n\n![alt text](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSdLGiada5O-NcK23jD9MsHJJ9uzmJ9C5qoKg&usqp=CAU \"Logo Title Text 1\")\n\n\n\n\n*This program based on using AI to make life simpler.*\n\n### THE TARGET\n\nThe purpose of this project was to produce a classification model that detects a journey type from from phone sensor readings.\n    \nThe categories of journey we are trying to classify are;\n\n1. On a train\n2. On the road (e.g. bus/car)\n3. Walking\n4. Sitting still\n\n![alt text](https://lh3.googleusercontent.com/proxy/MaaNQto0VBhOXQWmItpPckeVP1EjgNMn0hQmWRGAtZSFQWxGE20o8U9ummO7hoOHLgLJ_Csy_oNec0XE_Dqt9xxnUkZ1eVF1rIxxKs16-WGp0yy0DKJsAVpXvjy6d6VCBBjAh3Xq \"Logo Title Text 1\")\n\n### THE DATA\n\nWe used a set of 229151 sensor readings taken from 100's of different journeys to train our model. The data set we used can be seen here.\n\n![alt text](https://www.researchgate.net/profile/Charith-Perera-2/publication/234017923/figure/fig2/AS:667614586101765@1536183129256/Sensors-in-Mobile-Phones.png \"Logo Title Text 1\")\n\n\n### WHAT WE DID WITH THE DATA\n\nWe first ran some functions on the data to decide where a recording started and ended, this would prove vital\nlater for getting consistencies over time windows as the dataset was organised in such a way that time had lost\nit's true meaning.\n\nIn later production when we take live data from a device this step will not be necessary. We did it at this stage of development to replicate sequential sensor readings as the original data sometimes is not correctly ordered.\n\n![alt text](https://files.realpython.com/media/How-to-Plot-With-Pandas_Watermarked.f283f64b4ae3.jpg \"Logo Title Text 1\")\n\n\n### HALT, DATA LEAKS!\n\nOur first models ran at 97-99% accuracy with no tuning, we were incredibly suspicous of our results. We isolated a new user that the model hasn't seen before we found that 'user traits' were leaking test data to our training model.\n\nWe then took the approach to isolate individual users for testing, our predictions dropped to 45% accuracy, now we had some work to do!\n\nAfter taking sometime to analyze the feature importance and different combination of ML models we were able to improve this upto a whopping 85.14% over 4 classes and 97% over 3 classes.\n\n![alt text](https://www.zivver.eu/hubfs/Data_Breach_vs.%20Data_leak_explained_zivve_blog_en.jpg \"Logo Title Text 1\")\n",
   "metadata": {
    "tags": [],
    "cell_id": "00001-47d4cf4c-7154-4256-8f58-e0c3085df433",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=dd66c499-8cd9-44d2-87d5-ecc9c3ddd387' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "5ac4ba52-ac5f-45d0-9909-ab0231f73491",
  "deepnote_execution_queue": []
 }
}